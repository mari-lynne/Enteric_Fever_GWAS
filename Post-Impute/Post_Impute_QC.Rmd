---
title: "Post-Impute"
author: "Mari Johnson"
date: "11/03/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '~/GWAS_22/new_gwas/Post-imp/Merged')
```

```{r Set UP}
library(data.table)
library(stringr)
library(dplyr)
library(plinkQC)

#PLINKQC Set up
indir<-"~/GWAS_22/new_gwas/Post-imp/Merged"
qcdir<-"~/GWAS_22/new_gwas/Post-imp/Merged"
name<-"VAST_concat"
path2plink <- "/home/mari/bin/plink"

```

```{r}
fail_markers <- perMarkerQC(indir=indir, qcdir=qcdir, name=name,
                            path2plink=path2plink, mafTh = 0.05,
                            verbose=TRUE, interactive=TRUE,
                            showPlinkOutput=FALSE)
fail_markers$p_markerQC

```


plink2 --bfile VAST_concat --geno 0.1 --mind 0.1 --make-bed --out VAST_imp_QC
plink2 --bfile VAST_imp_QC --geno 0.05 --mind 0.05 --maf 0.01 --make-bed --out VAST_imp_QC2

#filter SNPs that are missing from 0.1% of individuals
#0 varients removed? Is this because I filtered pre-imputation, gives better imputation accuract

plink2 --bfile maf_filtered_data \
     --hwe 1e-25 keep-fewhet \
     --make-bed \
     --out hwe_filtered_data

plink2 --bfile P1T1 --geno 0.1 --mind 0.1 --make-bed --out P1T1_imp_QC
plink2 --bfile P1T1_imp_QC --geno 0.05 --mind 0.05 --maf 0.01 --make-bed --out P1T1_imp_QC2
#SNPs missing from 5% of population MAF <5 %
#So out of 340 the SNPs would have to be in 12 people
#10% cut off is probably better for assoc analysis in 34 people

7944509 variants removed due to allele frequency threshold(s)
(--maf/--max-maf/--mac/--max-mac).
895,0259 variants remaining after main filters.
((16894768 - 7944509)/16894768)*100 = 52% removed

#VAST

16873950 variants loaded from VAST_imp_QC.bim.
7396147 variants removed due to allele frequency threshold(s)
(--maf/--max-maf/--mac/--max-mac).
947,7803 variants remaining after main filters.

#merge

plink --bfile VAST_imp_QC2 --bmerge P1T1_imp_QC2 --out enteric
#This has mostly worked!! 9 million SNPs imputed



